# -*- coding: utf-8 -*-
"""Clustering Algorithm for Customer Segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bQIF0RfJMC_TVlTvCj2pN1xU1UIgeNAb
"""

# Commented out IPython magic to ensure Python compatibility.
#Importing the necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from mpl_toolkits.mplot3d import Axes3D
# %matplotlib inline

df=pd.read_excel("/content/marketing_campaign.xlsx")
df.head()

df.tail()

df.columns

df.info()

#We convert Dt_Customer into a datetime format.
df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'])
df.head()

df.tail()

#Univariate Alaysis
df.describe()

"""we see that Z_CostContact and Z_Revenue does not have any variance. 
Because of this, we easily remove it from the dataset.
"""

df.drop(['Z_CostContact', 'Z_Revenue'], axis=1, inplace=True)

df.isna().sum()

"""missing count 24

"""

#removing missing value
df = df[df['Income'].notnull()]
df.reset_index(drop=True, inplace=True)
df

df.describe(exclude='number')

df['Year'] = df['Dt_Customer'].apply(lambda row: row.year)
df

df[['Year']].describe()

sns.countplot(df['Year'])
plt.xlabel('Year')
plt.ylabel('count')

df['Age'] = df['Year'] - df['Year_Birth']
df

"""Data Visualization"""

visualization_df = df.copy()
visualization_df

visualization_df.drop(['ID','Year_Birth','Education','Marital_Status','Dt_Customer','Year'],axis=1, inplace=True)

visualization_df.rename({'MntWines': 'WineRank','MntFruits': 'FruitsRank','MntMeatProducts': 'MeatRank','MntFishProducts': 'FishRank','MntSweetProducts': 'SweetRank',
                         'MntGoldProds': 'GoldRank','NumWebPurchases': 'WebRank','NumCatalogPurchases': 'CatalogRank','NumStorePurchases': 'StoreRank'}, axis=1, inplace=True)
visualization_df

sns.displot(visualization_df['Recency'])

visualization_df.drop(['Recency'], axis=1, inplace=True)
visualization_df

sns.distplot(df['Income'])

outlier_idx = visualization_df[visualization_df['Income'] > 150000].index
visualization_df.drop(outlier_idx, inplace=True)

sns.distplot(visualization_df['Income'])

sns.distplot(df['Age'])

outlier_age = visualization_df.loc[visualization_df['Age'] > 90].index
visualization_df.drop(outlier_age, inplace=True)
visualization_df.reset_index(drop=True, inplace=True)

sns.distplot(visualization_df['Age'])

sns.countplot(visualization_df['Kidhome'])

sns.countplot(visualization_df['Teenhome'])

sns.countplot(visualization_df['NumDealsPurchases'])

visualization_df['Kidhome'] = visualization_df['Kidhome'].apply(lambda row: 1 if row >= 1 else 0)
visualization_df['Teenhome'] = visualization_df['Teenhome'].apply(lambda row: 1 if row >= 1 else 0)

visualization_df

"""**Cluster Analysis**"""

from sklearn.manifold import TSNE, LocallyLinearEmbedding, MDS, Isomap
from sklearn.preprocessing import StandardScaler

Cluster_Analysis_df = visualization_df.copy()
Cluster_Analysis_df

num_col = ['Income', 'Age', 'NumDealsPurchases', 'NumWebVisitsMonth']
cat_col = ['Kidhome', 'Teenhome', 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response', 'Complain']

Cluster_Analysis_df['Accepted'] = Cluster_Analysis_df[['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response']].sum(axis=1) > 0
Cluster_Analysis_df['Accepted'] = Cluster_Analysis_df['Accepted'].apply(lambda row: 1 if row else 0)

Cluster_Analysis_df.drop(['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response'], axis=1, inplace=True)

Cluster_Analysis_df

Cluster_Analysis_df = pd.DataFrame(StandardScaler().fit_transform(Cluster_Analysis_df), columns=Cluster_Analysis_df.columns)

for i in Cluster_Analysis_df.columns:
    Cluster_Analysis_df[i].astype(dtype=float)

Cluster_Analysis_df.info()

from sklearn.decomposition import PCA
pca = PCA(n_components=10)
pca_df = pd.DataFrame(pca.fit_transform(Cluster_Analysis_df))
plt.plot(pca.explained_variance_ratio_.cumsum())
Cluster_Analysis_df = pd.concat([Cluster_Analysis_df, pca_df], axis=1)

Cluster_Analysis_df

tsne = TSNE(learning_rate=50)
tsne_results = Cluster_Analysis_df.copy()
tsne_results[['TSNE1', 'TSNE2']] = pd.DataFrame(tsne.fit_transform(Cluster_Analysis_df[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]), columns=['TSNE1', 'TSNE2'])
tsne_results

plt.figure(figsize=(10,10))
sns.scatterplot(x='TSNE1', y='TSNE2', hue='Accepted', data=tsne_results)
plt.show()

from scipy.cluster.vq import kmeans, vq
import random
random.seed(1000)
# All Data
cluster_data = Cluster_Analysis_df.copy()
distortions = []
for k in range(1, 15):
    _, distortion = kmeans(cluster_data, k)
    distortions.append(distortion)
    
plt.plot(distortions, label='All Data')

# Some Meaningful only
cluster_data = Cluster_Analysis_df.copy()[[
    'Kidhome', 'Teenhome', 'Complain', 'Accepted'
]]


distortions = []
for k in range(1, 15):
    _, distortion = kmeans(cluster_data, k)
    distortions.append(distortion)
    
plt.plot(distortions, label='Home Only')


# PCA Only
cluster_data = Cluster_Analysis_df.copy()[[
    0, 1, 2, 3, 4, 5, 6, 7
]]

distortions = []
for k in range(1, 15):
    _, distortion = kmeans(cluster_data, k)
    distortions.append(distortion)
    
plt.plot(distortions, label='PCA Only')

random.seed(500)
cluster_data = Cluster_Analysis_df [['Kidhome', 'Teenhome', 'Complain', 'Accepted']]
cluster_centers, _ = kmeans(cluster_data, 5)
cluster_data['cluster_labels'], _ = vq(cluster_data, cluster_centers)
tsne = TSNE(learning_rate=100)
tsne_results = cluster_data.copy()
tsne_results[['TSNE1', 'TSNE2']] = pd.DataFrame(tsne.fit_transform(Cluster_Analysis_df), columns=['TSNE1', 'TSNE2'])
plt.figure(figsize=(10,10))
sns.scatterplot(x='TSNE1', y='TSNE2', hue='cluster_labels', cmap=sns.color_palette(), data=tsne_results)
plt.show()

random.seed(500)
cluster_data = Cluster_Analysis_df.copy()[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]
cluster_centers, _ = kmeans(cluster_data, 5)
cluster_data['cluster_labels'], _ = vq(cluster_data, cluster_centers)
tsne = TSNE(learning_rate=100)
tsne_results = cluster_data.copy()
tsne_results[['TSNE1', 'TSNE2']] = pd.DataFrame(tsne.fit_transform(Cluster_Analysis_df),columns=['TSNE1', 'TSNE2'])
plt.figure(figsize=(10,10))
sns.scatterplot(x='TSNE1', y='TSNE2', hue='cluster_labels', cmap=sns.color_palette(), data=tsne_results)
plt.show()

"""We see that we have clustered the Customers quite well. However, there may be better things to do this clustering. We cannot determine how many we want and just guess segmentation to 5 categories. We see that the clustering with just 4 Features is quite amazing. We keep this clustering. I suggest for a better performing model to be put in an sklearn pipeline with just the Kidhome, Teenhome, Complain, and Accepted Features."""